{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# file_list = [(\"BLS12\", \"./bls12/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"BN\", \"./bn/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"MNT4\", \"./mnt4/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"MNT6\", \"./mnt6/monte_carlo_f_exp_50000.csv\")]\n",
    "\n",
    "file_list = [(\"BLS12\", \"./bls12/monte_carlo_f_exp_55000.csv\"),\n",
    "            (\"BN\", \"./bn/monte_carlo_f_exp_55000.csv\"),\n",
    "            (\"MNT4\", \"./mnt4/monte_carlo_f_exp_100000.csv\"),\n",
    "            (\"MNT6\", \"./mnt6/monte_carlo_f_exp_100000.csv\")]\n",
    "\n",
    "\n",
    "\n",
    "def get_dfs(files):\n",
    "    results = []\n",
    "    for file in files:\n",
    "        (name, path) = file;\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[df[\"x_is_negative\"] == 1.0]\n",
    "        #df.loc[:,\"num_pairs\"] *= 0.5\n",
    "        df.drop(\"x_is_negative\", axis = 1, inplace = True)\n",
    "        results.append(df)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "def factor_out_final_exp(df, group_by = 3, skip_bad_fits = False):\n",
    "    df_final_exps = pd.DataFrame(columns = df.columns);\n",
    "    df_final_exps.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_final_exps.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_final_exps[\"final_exp_time\"] = 0.0\n",
    "\n",
    "    df_miller_loops = pd.DataFrame(columns = df.columns);\n",
    "    df_miller_loops.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_miller_loops.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_miller_loops[\"single_pair_miller_time\"] = 0.0\n",
    "\n",
    "    min_score = 1.0\n",
    "\n",
    "    for k,g in df.groupby(np.arange(len(df))//group_by):\n",
    "#         reg = linear_model.LinearRegression(fit_intercept = True)\n",
    "#         model = reg.fit(g[\"num_pairs\"][:, np.newaxis], g[\"run_microseconds\"][:, np.newaxis])\n",
    "        \n",
    "        model = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n",
    "            positive=True, random_state=9999, selection='random')\n",
    "        model.fit(g[\"num_pairs\"][:, np.newaxis], g[\"run_microseconds\"][:, np.newaxis])\n",
    "        \n",
    "        score = model.score(g[\"num_pairs\"][:, np.newaxis], g[\"run_microseconds\"][:, np.newaxis])\n",
    "        if score < min_score:\n",
    "            min_score = score\n",
    "            \n",
    "        if score < 0.85 and skip_bad_fits:\n",
    "#             print(g[\"num_pairs\"])\n",
    "#             print(g[\"run_microseconds\"])\n",
    "            continue\n",
    "            \n",
    "        slope = model.coef_[0];\n",
    "        intercept = model.intercept_[0];\n",
    "        \n",
    "        if slope <= 1 or intercept <= 1:\n",
    "            continue\n",
    "            \n",
    "        g_miller = g.iloc[0].copy()\n",
    "        g_miller.drop(\"run_microseconds\", inplace = True)\n",
    "        g_final_exp = g.iloc[0].copy()\n",
    "        g_final_exp.drop(\"run_microseconds\", inplace = True)\n",
    "\n",
    "#         g_miller[\"single_pair_miller_time\"] = model.coef_[0][0];\n",
    "        g_miller[\"single_pair_miller_time\"] = slope;\n",
    "        \n",
    "        g_final_exp[\"final_exp_time\"] = intercept;\n",
    "\n",
    "        g_miller.drop(\"num_pairs\", inplace = True)\n",
    "        g_final_exp.drop(\"num_pairs\", inplace = True)\n",
    "\n",
    "        df_miller_loops = df_miller_loops.append(g_miller, verify_integrity=True)\n",
    "        df_final_exps = df_final_exps.append(g_final_exp, verify_integrity=True)\n",
    "        \n",
    "    print(\"Minimal final exp fitting score = {}\".format(min_score))\n",
    "        \n",
    "    return (df_miller_loops, df_final_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "def factor_out_final_exp_non_negative(df, group_by = 3, skip_bad_fits = False):\n",
    "    df_final_exps = pd.DataFrame(columns = df.columns);\n",
    "    df_final_exps.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_final_exps.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_final_exps[\"final_exp_time\"] = 0.0\n",
    "\n",
    "    df_miller_loops = pd.DataFrame(columns = df.columns);\n",
    "    df_miller_loops.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_miller_loops.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_miller_loops[\"single_pair_miller_time\"] = 0.0\n",
    "\n",
    "    min_score = 1.0\n",
    "\n",
    "    for k,g in df.groupby(np.arange(len(df))//group_by):\n",
    "        g_copy = pd.DataFrame(g[\"num_pairs\"])\n",
    "        g_copy[\"intercept\"] = 1.0\n",
    "        \n",
    "        model, res = nnls(g_copy[[\"num_pairs\", \"intercept\"]][:], g[\"run_microseconds\"][:])\n",
    "            \n",
    "        g_miller = g.iloc[0].copy()\n",
    "        g_miller.drop(\"run_microseconds\", inplace = True)\n",
    "        g_final_exp = g.iloc[0].copy()\n",
    "        g_final_exp.drop(\"run_microseconds\", inplace = True)\n",
    "        \n",
    "        g_miller[\"single_pair_miller_time\"] = model[0];\n",
    "        g_final_exp[\"final_exp_time\"] = model[1];\n",
    "\n",
    "        g_miller.drop(\"num_pairs\", inplace = True)\n",
    "        g_final_exp.drop(\"num_pairs\", inplace = True)\n",
    "\n",
    "        df_miller_loops = df_miller_loops.append(g_miller, verify_integrity=True)\n",
    "        df_final_exps = df_final_exps.append(g_final_exp, verify_integrity=True)\n",
    "        \n",
    "    print(\"Minimal final exp fitting score = {}\".format(min_score))\n",
    "        \n",
    "    return (df_miller_loops, df_final_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_dfs(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>22083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>36677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>15900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>22633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_bit_length  x_hamming_weight  modulus_limbs  group_limbs  num_pairs  \\\n",
       "0            57                39              6           16          2   \n",
       "1            57                39              6           16          4   \n",
       "2            57                39              6           16          6   \n",
       "3            64                 7              7           11          2   \n",
       "4            64                 7              7           11          4   \n",
       "\n",
       "   run_microseconds  \n",
       "0             22083  \n",
       "1             25577  \n",
       "2             36677  \n",
       "3             15900  \n",
       "4             22633  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>six_u_plus_two_bit_length</th>\n",
       "      <th>six_u_plus_two_hamming</th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>25174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>28713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>34342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   six_u_plus_two_bit_length  six_u_plus_two_hamming  modulus_limbs  \\\n",
       "0                         51                      29             10   \n",
       "1                         51                      29             10   \n",
       "2                         51                      29             10   \n",
       "3                          5                       1              6   \n",
       "4                          5                       1              6   \n",
       "\n",
       "   group_limbs  num_pairs  x_bit_length  x_hamming_weight  run_microseconds  \n",
       "0            2          2            49                29             25174  \n",
       "1            2          4            49                29             28713  \n",
       "2            2          6            49                29             34342  \n",
       "3            4          2             2                 2              7393  \n",
       "4            4          4             2                 2              8684  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>exp_w0_bit_length</th>\n",
       "      <th>exp_w0_hamming</th>\n",
       "      <th>exp_w0_is_negative</th>\n",
       "      <th>exp_w1_bit_length</th>\n",
       "      <th>exp_w1_hamming</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>18532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>34374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>67828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>136585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>207514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "      <td>449</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>1184</td>\n",
       "      <td>489</td>\n",
       "      <td>268734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>22266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>39178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>75236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>140665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>212582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>480</td>\n",
       "      <td>38</td>\n",
       "      <td>1795</td>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>748</td>\n",
       "      <td>276853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>615</td>\n",
       "      <td>226</td>\n",
       "      <td>1277</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>629</td>\n",
       "      <td>14262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>615</td>\n",
       "      <td>226</td>\n",
       "      <td>1277</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>629</td>\n",
       "      <td>27456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>615</td>\n",
       "      <td>226</td>\n",
       "      <td>1277</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>629</td>\n",
       "      <td>52553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    modulus_limbs  group_limbs  num_pairs  x_bit_length  x_hamming_weight  \\\n",
       "0               4            5          2           890               597   \n",
       "1               4            5          4           890               597   \n",
       "2               4            5          8           890               597   \n",
       "3               4            5         16           890               597   \n",
       "4               4            5         24           890               597   \n",
       "5               4            5         32           890               597   \n",
       "6               9            1          2           480                38   \n",
       "7               9            1          4           480                38   \n",
       "8               9            1          8           480                38   \n",
       "9               9            1         16           480                38   \n",
       "10              9            1         24           480                38   \n",
       "11              9            1         32           480                38   \n",
       "12              4            9          2           615               226   \n",
       "13              4            9          4           615               226   \n",
       "14              4            9          8           615               226   \n",
       "\n",
       "    exp_w0_bit_length  exp_w0_hamming  exp_w0_is_negative  exp_w1_bit_length  \\\n",
       "0                 449             446                   1               1184   \n",
       "1                 449             446                   1               1184   \n",
       "2                 449             446                   1               1184   \n",
       "3                 449             446                   1               1184   \n",
       "4                 449             446                   1               1184   \n",
       "5                 449             446                   1               1184   \n",
       "6                1795            1644                   1               1002   \n",
       "7                1795            1644                   1               1002   \n",
       "8                1795            1644                   1               1002   \n",
       "9                1795            1644                   1               1002   \n",
       "10               1795            1644                   1               1002   \n",
       "11               1795            1644                   1               1002   \n",
       "12               1277             535                   1               1299   \n",
       "13               1277             535                   1               1299   \n",
       "14               1277             535                   1               1299   \n",
       "\n",
       "    exp_w1_hamming  run_microseconds  \n",
       "0              489             18532  \n",
       "1              489             34374  \n",
       "2              489             67828  \n",
       "3              489            136585  \n",
       "4              489            207514  \n",
       "5              489            268734  \n",
       "6              748             22266  \n",
       "7              748             39178  \n",
       "8              748             75236  \n",
       "9              748            140665  \n",
       "10             748            212582  \n",
       "11             748            276853  \n",
       "12             629             14262  \n",
       "13             629             27456  \n",
       "14             629             52553  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[2].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>exp_w0_bit_length</th>\n",
       "      <th>exp_w0_hamming</th>\n",
       "      <th>exp_w0_is_negative</th>\n",
       "      <th>exp_w1_bit_length</th>\n",
       "      <th>exp_w1_hamming</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>459967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>895641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>1769895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>3548325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>5311679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>1752</td>\n",
       "      <td>738</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1320</td>\n",
       "      <td>669</td>\n",
       "      <td>6918569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>229753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>437527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>842665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>1694210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>2511266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>487</td>\n",
       "      <td>258</td>\n",
       "      <td>511</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "      <td>1174</td>\n",
       "      <td>3305020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1390</td>\n",
       "      <td>1193</td>\n",
       "      <td>1383</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>1147</td>\n",
       "      <td>344</td>\n",
       "      <td>420497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1390</td>\n",
       "      <td>1193</td>\n",
       "      <td>1383</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>1147</td>\n",
       "      <td>344</td>\n",
       "      <td>800868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1390</td>\n",
       "      <td>1193</td>\n",
       "      <td>1383</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>1147</td>\n",
       "      <td>344</td>\n",
       "      <td>1572674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    modulus_limbs  group_limbs  num_pairs  x_bit_length  x_hamming_weight  \\\n",
       "0              16            8          2          1752               738   \n",
       "1              16            8          4          1752               738   \n",
       "2              16            8          8          1752               738   \n",
       "3              16            8         16          1752               738   \n",
       "4              16            8         24          1752               738   \n",
       "5              16            8         32          1752               738   \n",
       "6              15           16          2           487               258   \n",
       "7              15           16          4           487               258   \n",
       "8              15           16          8           487               258   \n",
       "9              15           16         16           487               258   \n",
       "10             15           16         24           487               258   \n",
       "11             15           16         32           487               258   \n",
       "12             15            7          2          1390              1193   \n",
       "13             15            7          4          1390              1193   \n",
       "14             15            7          8          1390              1193   \n",
       "\n",
       "    exp_w0_bit_length  exp_w0_hamming  exp_w0_is_negative  exp_w1_bit_length  \\\n",
       "0                  86              17                   1               1320   \n",
       "1                  86              17                   1               1320   \n",
       "2                  86              17                   1               1320   \n",
       "3                  86              17                   1               1320   \n",
       "4                  86              17                   1               1320   \n",
       "5                  86              17                   1               1320   \n",
       "6                 511             491                   1               1808   \n",
       "7                 511             491                   1               1808   \n",
       "8                 511             491                   1               1808   \n",
       "9                 511             491                   1               1808   \n",
       "10                511             491                   1               1808   \n",
       "11                511             491                   1               1808   \n",
       "12               1383             961                   1               1147   \n",
       "13               1383             961                   1               1147   \n",
       "14               1383             961                   1               1147   \n",
       "\n",
       "    exp_w1_hamming  run_microseconds  \n",
       "0              669            459967  \n",
       "1              669            895641  \n",
       "2              669           1769895  \n",
       "3              669           3548325  \n",
       "4              669           5311679  \n",
       "5              669           6918569  \n",
       "6             1174            229753  \n",
       "7             1174            437527  \n",
       "8             1174            842665  \n",
       "9             1174           1694210  \n",
       "10            1174           2511266  \n",
       "11            1174           3305020  \n",
       "12             344            420497  \n",
       "13             344            800868  \n",
       "14             344           1572674  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[3].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_df(df):\n",
    "    train, test = train_test_split(\n",
    "        df, test_size=0.10, random_state=42)\n",
    "    \n",
    "    print(\"Train samples {}, test samples {}\".format(len(train), len(test)))\n",
    "    \n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import max_error, mean_absolute_error, r2_score\n",
    "\n",
    "def pretty_print_polynomial(poly, model, variable_names):\n",
    "    terms = []\n",
    "\n",
    "    for term_idx in range(0, poly.powers_.shape[0]):\n",
    "        coeff = model.coef_[term_idx]\n",
    "        if coeff == 0:\n",
    "            continue\n",
    "        coeff = np.around(coeff, decimals=6)\n",
    "        subparts = []\n",
    "        coeff_string = \"{}\".format(coeff)\n",
    "        subparts.append(coeff_string)\n",
    "        for variable_idx in range(0, poly.powers_.shape[1]):\n",
    "            power = poly.powers_[term_idx, variable_idx]\n",
    "            if power != 0:\n",
    "                term_string = '{}^{}'.format(variable_names[variable_idx], power)\n",
    "                subparts.append(term_string)\n",
    "        if len(subparts) != 0:\n",
    "            joined = \" * \".join(subparts)\n",
    "            terms.append(joined)\n",
    "\n",
    "    polynomial_string = \" + \".join(terms)\n",
    "    print(polynomial_string)\n",
    "    \n",
    "\n",
    "\n",
    "def analyze(train, test, features, target, trunc_limit = 0.001, degree = 6):\n",
    "    poly = PolynomialFeatures(degree = degree, include_bias = False)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000,fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "\n",
    "    X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "    pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bls12(df):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\")\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\"], \"final_exp_time\")\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.0\n",
      "Train samples 12463, test samples 1385\n",
      "Fitting miller loop price\n",
      "score on training set 0.9734097577950763\n",
      "score on test set 0.9759022280372771\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 7614.571415982769 microseconds\n",
      "Mean absolute error 623.7407086228568 microseconds\n",
      "R2 score = 0.9759022280372771\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 7657.080830071041 microseconds\n",
      "Mean absolute error 621.2882814217483 microseconds\n",
      "R2 score = 0.9759987185889156\n",
      "0.417709 * x_bit_length^1 * modulus_limbs^1 + 0.017594 * x_hamming_weight^1 * modulus_limbs^1 + 18.306288 * modulus_limbs^1 * group_limbs^1 + 0.002166 * x_bit_length^1 * x_hamming_weight^1 * modulus_limbs^1 + 0.144132 * x_bit_length^1 * modulus_limbs^2 + 0.004641 * x_bit_length^1 * modulus_limbs^1 * group_limbs^1 + 0.174109 * x_hamming_weight^1 * modulus_limbs^2 + 4.846864 * modulus_limbs^2 * group_limbs^1 + 0.010811 * modulus_limbs^1 * group_limbs^2 + 0.001364 * modulus_limbs^2 * group_limbs^2\n",
      "Train samples 12463, test samples 1385\n",
      "Fitting final exp price\n",
      "score on training set 0.9426968824627547\n",
      "score on test set 0.9431432491701126\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 39112.69021009118 microseconds\n",
      "Mean absolute error 2440.485487192791 microseconds\n",
      "R2 score = 0.9431432491701126\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 39112.69021009118 microseconds\n",
      "Mean absolute error 2440.485487192791 microseconds\n",
      "R2 score = 0.9431432491701126\n",
      "3.942075 * x_bit_length^1 + 1.505175 * x_hamming_weight^1 + 15.113984 * modulus_limbs^1 + 1.865667 * x_bit_length^1 * modulus_limbs^1 + 4.120774 * x_hamming_weight^1 * modulus_limbs^1 + 59.540759 * modulus_limbs^2 + 0.284245 * x_bit_length^1 * modulus_limbs^2 + 0.496913 * x_hamming_weight^1 * modulus_limbs^2 + 5.009175 * modulus_limbs^3 + 0.009092 * x_bit_length^1 * modulus_limbs^3 + 0.016185 * modulus_limbs^4\n"
     ]
    }
   ],
   "source": [
    "(bls_miller, bls_final_exp) = analyze_bls12(dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bn(df):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"six_u_plus_two_bit_length\", \"six_u_plus_two_hamming\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\")\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\"], \"final_exp_time\")\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.005380826021653018\n",
      "Train samples 12294, test samples 1366\n",
      "Fitting miller loop price\n",
      "score on training set 0.974812367499273\n",
      "score on test set 0.9740105351972641\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 10138.032797187745 microseconds\n",
      "Mean absolute error 633.5917715631521 microseconds\n",
      "R2 score = 0.9740105351972641\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 10331.477741027258 microseconds\n",
      "Mean absolute error 629.5417292546151 microseconds\n",
      "R2 score = 0.9740552865611236\n",
      "0.194238 * six_u_plus_two_bit_length^1 * modulus_limbs^1 + 0.221893 * six_u_plus_two_hamming^1 * modulus_limbs^1 + 18.859488 * modulus_limbs^1 * group_limbs^1 + 0.00177 * six_u_plus_two_bit_length^1 * six_u_plus_two_hamming^1 * modulus_limbs^1 + 0.160538 * six_u_plus_two_bit_length^1 * modulus_limbs^2 + 0.154685 * six_u_plus_two_hamming^1 * modulus_limbs^2 + 4.87253 * modulus_limbs^2 * group_limbs^1\n",
      "Train samples 12294, test samples 1366\n",
      "Fitting final exp price\n",
      "score on training set 0.9337438926541602\n",
      "score on test set 0.9351525183207803\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 26613.493996327714 microseconds\n",
      "Mean absolute error 2379.21407313317 microseconds\n",
      "R2 score = 0.9351525183207803\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 26723.558629143386 microseconds\n",
      "Mean absolute error 2371.6505422034475 microseconds\n",
      "R2 score = 0.935467918958256\n",
      "2.523658 * x_bit_length^1 + 2.862805 * x_hamming_weight^1 + 64.942954 * modulus_limbs^1 + 1.658588 * x_bit_length^1 * modulus_limbs^1 + 1.196372 * x_hamming_weight^1 * modulus_limbs^1 + 58.574598 * modulus_limbs^2 + 0.213338 * x_bit_length^1 * modulus_limbs^2 + 0.328796 * x_hamming_weight^1 * modulus_limbs^2 + 5.034872 * modulus_limbs^3 + 0.002038 * x_bit_length^1 * modulus_limbs^3 + 0.002797 * x_hamming_weight^1 * modulus_limbs^3 + 0.05634 * modulus_limbs^4\n"
     ]
    }
   ],
   "source": [
    "(bn_miller, bn_final_exp) = analyze_bn(dataframes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt(df, trunc_limit = 0.001, skip_bad_fits = False):\n",
    "    (miller, final_exp) = factor_out_final_exp(df, group_by = 6, skip_bad_fits = skip_bad_fits)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"exp_w0_bit_length\", \"exp_w0_hamming\", \"exp_w1_bit_length\", \"exp_w1_hamming\", \"modulus_limbs\"], \"final_exp_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.0\n",
      "Train samples 29468, test samples 3275\n",
      "Fitting miller loop price\n",
      "score on training set 0.9966190639346156\n",
      "score on test set 0.9963893679680819\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 12612.867689504259 microseconds\n",
      "Mean absolute error 1135.9836354343354 microseconds\n",
      "R2 score = 0.9963893679680818\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 47540.19537147235 microseconds\n",
      "Mean absolute error 4395.452396482143 microseconds\n",
      "R2 score = 0.9170334811543186\n",
      "0.212922 * x_bit_length^1 + 0.977996 * x_bit_length^1 * modulus_limbs^1 + 0.707895 * x_hamming_weight^1 * modulus_limbs^1 + 43.642287 * modulus_limbs^1 * group_limbs^1 + 0.040712 * x_bit_length^1 * modulus_limbs^2 + 0.001622 * x_bit_length^1 * modulus_limbs^1 * group_limbs^1 + 0.066906 * x_hamming_weight^1 * modulus_limbs^2 + 3.573559 * modulus_limbs^2 * group_limbs^1 + 0.001904 * x_bit_length^1 * modulus_limbs^3 + 0.05676 * modulus_limbs^3 * group_limbs^1 + 0.015282 * modulus_limbs^2 * group_limbs^2\n",
      "Train samples 29468, test samples 3275\n",
      "Fitting final exp price\n",
      "score on training set 0.024626742403079604\n",
      "score on test set 0.01991698336265868\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 115576.43528168729 microseconds\n",
      "Mean absolute error 12798.263131241962 microseconds\n",
      "R2 score = 0.01991698336265868\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 115576.43528168729 microseconds\n",
      "Mean absolute error 12798.263131241962 microseconds\n",
      "R2 score = 0.01991698336265868\n",
      "1.958497 * exp_w0_bit_length^1 + 0.53794 * exp_w0_hamming^1 + 1.824602 * exp_w1_bit_length^1 + 0.227964 * exp_w1_hamming^1 + 1141.593427 * modulus_limbs^1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Minimal final exp fitting score = 0.0\n",
      "Train samples 29468, test samples 3275\n",
      "Fitting miller loop price\n",
      "score on training set 0.9966190639346156\n",
      "score on test set 0.9963893679680819\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 12612.867689504259 microseconds\n",
      "Mean absolute error 1135.9836354343354 microseconds\n",
      "R2 score = 0.9963893679680818\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 12612.867689504259 microseconds\n",
      "Mean absolute error 1135.9836354343354 microseconds\n",
      "R2 score = 0.9963893679680818\n",
      "0.212922 * x_bit_length^1 + 0.977996 * x_bit_length^1 * modulus_limbs^1 + 0.707895 * x_hamming_weight^1 * modulus_limbs^1 + 43.642287 * modulus_limbs^1 * group_limbs^1 + 1.7e-05 * x_bit_length^2 * modulus_limbs^1 + 0.040712 * x_bit_length^1 * modulus_limbs^2 + 0.001622 * x_bit_length^1 * modulus_limbs^1 * group_limbs^1 + 0.066906 * x_hamming_weight^1 * modulus_limbs^2 + 3.573559 * modulus_limbs^2 * group_limbs^1 + 0.001904 * x_bit_length^1 * modulus_limbs^3 + 9e-06 * x_bit_length^1 * modulus_limbs^2 * group_limbs^1 + 0.0 * x_hamming_weight^2 * modulus_limbs^2 + 0.05676 * modulus_limbs^3 * group_limbs^1 + 0.015282 * modulus_limbs^2 * group_limbs^2 + 7.9e-05 * x_bit_length^1 * modulus_limbs^4 + 0.0 * x_hamming_weight^3 * modulus_limbs^2 + 7e-06 * x_bit_length^1 * modulus_limbs^5 + 0.0 * x_hamming_weight^4 * modulus_limbs^2 + 9e-06 * x_hamming_weight^1 * modulus_limbs^5 + 1.3e-05 * modulus_limbs^6 + 0.000359 * modulus_limbs^5 * group_limbs^1\n",
      "Train samples 29468, test samples 3275\n",
      "Fitting final exp price\n",
      "score on training set 0.024626742403079604\n",
      "score on test set 0.01991698336265868\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 115576.43528168729 microseconds\n",
      "Mean absolute error 12798.263131241962 microseconds\n",
      "R2 score = 0.01991698336265868\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 115576.43528168729 microseconds\n",
      "Mean absolute error 12798.263131241962 microseconds\n",
      "R2 score = 0.01991698336265868\n",
      "1.958497 * exp_w0_bit_length^1 + 0.53794 * exp_w0_hamming^1 + 1.824602 * exp_w1_bit_length^1 + 0.227964 * exp_w1_hamming^1 + 1141.593427 * modulus_limbs^1\n"
     ]
    }
   ],
   "source": [
    "(mnt4_miller, mnt4_final_exp) = analyze_mnt(dataframes[2], trunc_limit = 0.001, skip_bad_fits = True)\n",
    "print(\"\\n\\n\\n\")\n",
    "(mnt4_miller, mnt4_final_exp) = analyze_mnt(dataframes[2], trunc_limit = 0.0, skip_bad_fits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.0\n",
      "Train samples 33059, test samples 3674\n",
      "Fitting miller loop price\n",
      "score on training set 0.9881950088343412\n",
      "score on test set 0.9886002555395369\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 41392.449385947344 microseconds\n",
      "Mean absolute error 3654.072324593691 microseconds\n",
      "R2 score = 0.9886002555395369\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 40131.02170133125 microseconds\n",
      "Mean absolute error 3996.5745826919983 microseconds\n",
      "R2 score = 0.9875753753310927\n",
      "0.386594 * x_hamming_weight^1 + 0.566254 * x_bit_length^1 * modulus_limbs^1 + 0.077422 * x_bit_length^1 * group_limbs^1 + 0.332178 * x_hamming_weight^1 * modulus_limbs^1 + 0.042431 * x_hamming_weight^1 * group_limbs^1 + 3.699187 * group_limbs^2 + 0.275471 * x_bit_length^1 * modulus_limbs^2 + 0.247976 * x_hamming_weight^1 * modulus_limbs^2 + 12.326227 * modulus_limbs^2 * group_limbs^1 + 0.08341 * modulus_limbs^2 * group_limbs^2\n",
      "Train samples 33059, test samples 3674\n",
      "Fitting final exp price\n",
      "score on training set -0.04029738917503023\n",
      "score on test set -0.03624089589409918\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 1416738.6653680736 microseconds\n",
      "Mean absolute error 142527.72421377577 microseconds\n",
      "R2 score = -0.03624089589409918\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 1416738.6653680736 microseconds\n",
      "Mean absolute error 142527.72421377577 microseconds\n",
      "R2 score = -0.03624089589409918\n",
      "31.911017 * exp_w0_bit_length^1 + 1.642847 * exp_w0_hamming^1 + 34.355429 * exp_w1_bit_length^1 + 5158.338661 * modulus_limbs^1\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4e287f57d0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmnt6_miller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnt6_final_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_mnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mmnt6_miller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnt6_final_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_mnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-a19a082dc067>\u001b[0m in \u001b[0;36manalyze_mnt\u001b[0;34m(df, trunc_limit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyze_mnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mmiller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor_out_final_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_by\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmiller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting miller loop price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_miller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"x_bit_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x_hamming_weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"modulus_limbs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"group_limbs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"single_pair_miller_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrunc_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-18bbc34da71f>\u001b[0m in \u001b[0;36mfactor_out_final_exp\u001b[0;34m(df, group_by, skip_bad_fits)\u001b[0m\n\u001b[1;32m     22\u001b[0m         model = Lasso(alpha=0.0001,precompute=True,max_iter=1000,\n\u001b[1;32m     23\u001b[0m             positive=True, random_state=9999, selection='random')\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_pairs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_microseconds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_pairs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_microseconds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    701\u001b[0m             X, y = check_X_y(X, y, accept_sparse='csc',\n\u001b[1;32m    702\u001b[0m                              \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                              copy=X_copied, multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    704\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[1;32m    705\u001b[0m                             ensure_2d=False)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 722\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n\u001b[0;32m--> 499\u001b[0;31m                                  \"{}\\n\".format(array))\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# It is possible that the np.array(..) gave no warning. This happens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/warnings.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot exit %r without entering first\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "(mnt6_miller, mnt6_final_exp) = analyze_mnt(dataframes[3], trunc_limit = 0.001)\n",
    "print(\"\\n\\n\\n\")\n",
    "(mnt6_miller, mnt6_final_exp) = analyze_mnt(dataframes[3], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_manual_poly(df, features_description, target, trunc_limit = 0.001, degree = 3):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    features = []\n",
    "    for feature in features_description:\n",
    "        name, max_power = feature\n",
    "        for i in range(1, max_power+1):\n",
    "            subname = \"{}^{}\".format(name, i)\n",
    "            new_df[subname] = new_df[name].apply(lambda x: x**i)\n",
    "            features.append(subname)\n",
    "            \n",
    "    print(features)\n",
    "            \n",
    "    poly = PolynomialFeatures(degree = degree, interaction_only=True, include_bias = False)\n",
    "        \n",
    "    train, test = split_df(new_df)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "    \n",
    "    X_train = poly.fit_transform(X_train)\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000, fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Intercept = {}\".format(lin.intercept_))\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "    \n",
    "    X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "    pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt_final_exp(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df, group_by = 6)\n",
    "\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze_manual_poly(final_exp, [\n",
    "        (\"exp_w0_bit_length\", 1), \n",
    "        (\"exp_w0_hamming\", 1), \n",
    "        (\"exp_w1_bit_length\", 1),\n",
    "        (\"exp_w1_hamming\", 1),\n",
    "        (\"modulus_limbs\", 12)], \"final_exp_time\", trunc_limit = trunc_limit, degree = 2)\n",
    "    \n",
    "    return model_final_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8c040817dc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnt4_final_exp_alt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_mnt_final_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(\"\\n\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5d891f4e8c44>\u001b[0m in \u001b[0;36manalyze_mnt_final_exp\u001b[0;34m(df, trunc_limit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyze_mnt_final_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mmiller\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor_out_final_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_by\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting final exp price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model_final_exp = analyze_manual_poly(final_exp, [\n",
      "\u001b[0;32m<ipython-input-2-18bbc34da71f>\u001b[0m in \u001b[0;36mfactor_out_final_exp\u001b[0;34m(df, group_by, skip_bad_fits)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mg_miller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mg_miller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_microseconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mg_final_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mg_final_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_microseconds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4319\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4320\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4321\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4322\u001b[0m         )\n\u001b[1;32m   4323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3913\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3915\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3945\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3947\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3948\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5327\u001b[0m         \u001b[0marr_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"object\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"object\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5328\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_labels_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5329\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5330\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2995\u001b[0m                 )\n\u001b[1;32m   2996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2997\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.001)\n",
    "# print(\"\\n\\n\\n\") \n",
    "# mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_manual_poly_separated(df, powered_features, linear_features, target, trunc_limit = 0.001):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    sub_features = []\n",
    "    for feature in powered_features:\n",
    "        name, max_power = feature\n",
    "        for i in range(1, max_power+1):\n",
    "            subname = \"{}^{}\".format(name, i)\n",
    "            new_df[subname] = new_df[name].apply(lambda x: x**i)\n",
    "            sub_features.append(subname)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for subfeature in sub_features:\n",
    "        for lin_feature in linear_features:\n",
    "            subname = \"{}*{}\".format(subfeature, lin_feature)\n",
    "            new_df[subname] = new_df.apply(lambda row: (row[subfeature]*row[lin_feature]), axis=1)\n",
    "            features.append(subname)\n",
    "            \n",
    "            \n",
    "    print(features)\n",
    "        \n",
    "    train, test = split_df(new_df)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000, fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Intercept = {}\".format(lin.intercept_))\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "#     pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt_final_exp_manual(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df, group_by = 6, skip_bad_fits = True)\n",
    "#     (miller, final_exp) = factor_out_final_exp_non_negative(df, skip_bad_fits = True)\n",
    "    \n",
    "    print(final_exp.head(25))\n",
    "\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze_manual_poly_separated(final_exp, [\n",
    "        (\"modulus_limbs\", 12)], \n",
    "          [\"exp_w0_bit_length\", \"exp_w0_hamming\",\"exp_w1_bit_length\",\"exp_w1_hamming\"],\n",
    "                              \"final_exp_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    return model_final_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.0\n",
      "     modulus_limbs  group_limbs  x_bit_length  x_hamming_weight  \\\n",
      "0              4.0          5.0         890.0             597.0   \n",
      "6              9.0          1.0         480.0              38.0   \n",
      "12             4.0          9.0         615.0             226.0   \n",
      "18             8.0          9.0        1185.0             634.0   \n",
      "24             9.0         16.0        1156.0             923.0   \n",
      "36             5.0          4.0        1097.0             288.0   \n",
      "42            13.0         14.0        1390.0            1011.0   \n",
      "48            13.0          4.0         470.0               3.0   \n",
      "60            11.0          5.0        1070.0             358.0   \n",
      "66            14.0          1.0         192.0              20.0   \n",
      "78            13.0          5.0        1888.0             161.0   \n",
      "84            16.0          1.0          24.0              12.0   \n",
      "96             7.0          7.0         729.0             668.0   \n",
      "108           10.0         14.0         108.0              45.0   \n",
      "114           14.0          7.0        1026.0             758.0   \n",
      "120            8.0         14.0        1529.0            1275.0   \n",
      "126            8.0          7.0         682.0             575.0   \n",
      "132           15.0          3.0        1971.0             160.0   \n",
      "138            5.0          2.0         639.0             371.0   \n",
      "150           10.0          3.0         460.0             305.0   \n",
      "156           11.0          5.0         164.0              88.0   \n",
      "162            5.0          3.0        1849.0            1470.0   \n",
      "168           13.0         15.0        1982.0            1001.0   \n",
      "180           10.0          9.0         347.0             249.0   \n",
      "186           14.0          6.0        1782.0            1346.0   \n",
      "\n",
      "     exp_w0_bit_length  exp_w0_hamming  exp_w0_is_negative  exp_w1_bit_length  \\\n",
      "0                449.0           446.0                 1.0             1184.0   \n",
      "6               1795.0          1644.0                 1.0             1002.0   \n",
      "12              1277.0           535.0                 1.0             1299.0   \n",
      "18               897.0           799.0                 1.0             1694.0   \n",
      "24              1941.0          1076.0                 1.0              391.0   \n",
      "36                55.0            49.0                 1.0             1309.0   \n",
      "42              1126.0            59.0                 1.0               29.0   \n",
      "48               146.0            30.0                 1.0             1939.0   \n",
      "60              1294.0           112.0                 1.0               45.0   \n",
      "66              1102.0           973.0                 1.0             1706.0   \n",
      "78              1306.0           681.0                 1.0             1202.0   \n",
      "84               512.0            51.0                 1.0              442.0   \n",
      "96              1417.0           370.0                 1.0               61.0   \n",
      "108              475.0            70.0                 1.0              614.0   \n",
      "114             1708.0           930.0                 1.0             2016.0   \n",
      "120              505.0           240.0                 1.0             1963.0   \n",
      "126              257.0            82.0                 1.0             1829.0   \n",
      "132             1843.0           137.0                 1.0              876.0   \n",
      "138             1712.0          1488.0                 1.0              246.0   \n",
      "150             1297.0           359.0                 1.0              289.0   \n",
      "156             1305.0            79.0                 1.0              485.0   \n",
      "162             1596.0           699.0                 1.0             1424.0   \n",
      "168              567.0           345.0                 1.0             1434.0   \n",
      "180              544.0           475.0                 1.0             1980.0   \n",
      "186              424.0           174.0                 1.0              512.0   \n",
      "\n",
      "     exp_w1_hamming  final_exp_time  \n",
      "0             489.0     1328.070700  \n",
      "6             748.0     5716.329890  \n",
      "12            629.0     2590.268627  \n",
      "18            903.0     4567.731398  \n",
      "24            294.0    10856.607929  \n",
      "36            115.0     1954.445818  \n",
      "42              3.0    17307.979277  \n",
      "48           1925.0     9104.556091  \n",
      "60              8.0     7750.755903  \n",
      "66             19.0    10698.110285  \n",
      "78            479.0    15215.221501  \n",
      "84            298.0     8813.555149  \n",
      "96             33.0     1310.239409  \n",
      "108           207.0     1277.926497  \n",
      "114           889.0    37109.900106  \n",
      "120           417.0    10216.523104  \n",
      "126           484.0     3827.793603  \n",
      "132           795.0    35303.058448  \n",
      "138           208.0     1026.772868  \n",
      "150            71.0     2376.469381  \n",
      "156           136.0     5196.139503  \n",
      "162           830.0      346.965139  \n",
      "168          1351.0    45066.249777  \n",
      "180          1452.0     7902.478806  \n",
      "186           384.0    52405.611699  \n",
      "Fitting final exp price\n",
      "['modulus_limbs^1*exp_w0_bit_length', 'modulus_limbs^1*exp_w0_hamming', 'modulus_limbs^1*exp_w1_bit_length', 'modulus_limbs^1*exp_w1_hamming', 'modulus_limbs^2*exp_w0_bit_length', 'modulus_limbs^2*exp_w0_hamming', 'modulus_limbs^2*exp_w1_bit_length', 'modulus_limbs^2*exp_w1_hamming', 'modulus_limbs^3*exp_w0_bit_length', 'modulus_limbs^3*exp_w0_hamming', 'modulus_limbs^3*exp_w1_bit_length', 'modulus_limbs^3*exp_w1_hamming', 'modulus_limbs^4*exp_w0_bit_length', 'modulus_limbs^4*exp_w0_hamming', 'modulus_limbs^4*exp_w1_bit_length', 'modulus_limbs^4*exp_w1_hamming', 'modulus_limbs^5*exp_w0_bit_length', 'modulus_limbs^5*exp_w0_hamming', 'modulus_limbs^5*exp_w1_bit_length', 'modulus_limbs^5*exp_w1_hamming', 'modulus_limbs^6*exp_w0_bit_length', 'modulus_limbs^6*exp_w0_hamming', 'modulus_limbs^6*exp_w1_bit_length', 'modulus_limbs^6*exp_w1_hamming', 'modulus_limbs^7*exp_w0_bit_length', 'modulus_limbs^7*exp_w0_hamming', 'modulus_limbs^7*exp_w1_bit_length', 'modulus_limbs^7*exp_w1_hamming', 'modulus_limbs^8*exp_w0_bit_length', 'modulus_limbs^8*exp_w0_hamming', 'modulus_limbs^8*exp_w1_bit_length', 'modulus_limbs^8*exp_w1_hamming', 'modulus_limbs^9*exp_w0_bit_length', 'modulus_limbs^9*exp_w0_hamming', 'modulus_limbs^9*exp_w1_bit_length', 'modulus_limbs^9*exp_w1_hamming', 'modulus_limbs^10*exp_w0_bit_length', 'modulus_limbs^10*exp_w0_hamming', 'modulus_limbs^10*exp_w1_bit_length', 'modulus_limbs^10*exp_w1_hamming', 'modulus_limbs^11*exp_w0_bit_length', 'modulus_limbs^11*exp_w0_hamming', 'modulus_limbs^11*exp_w1_bit_length', 'modulus_limbs^11*exp_w1_hamming', 'modulus_limbs^12*exp_w0_bit_length', 'modulus_limbs^12*exp_w0_hamming', 'modulus_limbs^12*exp_w1_bit_length', 'modulus_limbs^12*exp_w1_hamming']\n",
      "Train samples 28945, test samples 3217\n",
      "Intercept = 0.0\n",
      "score on training set -0.0427163536952202\n",
      "score on test set -0.05593176429347224\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 89851.21763825744 microseconds\n",
      "Mean absolute error 11064.071406800676 microseconds\n",
      "R2 score = -0.05593176429347224\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 89851.21763825744 microseconds\n",
      "Mean absolute error 11064.071406800676 microseconds\n",
      "R2 score = -0.05593176429347224\n"
     ]
    }
   ],
   "source": [
    "mnt4_final_exp_alt = analyze_mnt_final_exp_manual(dataframes[2], trunc_limit = 0.001)\n",
    "# print(\"\\n\\n\\n\") \n",
    "# mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnt_reduce_num_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"exp_bit_length\"] = new_df.apply(lambda row: (row[\"exp_w0_bit_length\"]+row[\"exp_w1_bit_length\"]), axis=1)\n",
    "    new_df[\"exp_hamming\"] = new_df.apply(lambda row: (row[\"exp_w0_hamming\"]+row[\"exp_w1_hamming\"]), axis=1)\n",
    "    new_df.drop(\"x_bit_length\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"x_hamming_weight\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"exp_w0_bit_length\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"exp_w1_bit_length\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"exp_w0_hamming\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"exp_w1_hamming\", axis = 1, inplace = True)\n",
    "    new_df.drop(\"exp_w0_is_negative\", axis = 1, inplace = True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt_final_exp_manual_reduced_features(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df, group_by = 6, skip_bad_fits = True)\n",
    "#     (miller, final_exp) = factor_out_final_exp_non_negative(df, skip_bad_fits = True)\n",
    "    \n",
    "    final_exp_reduced = mnt_reduce_num_features(final_exp)\n",
    "    print(final_exp_reduced.head(10))\n",
    "\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze_manual_poly_separated(final_exp_reduced, [\n",
    "        (\"modulus_limbs\", 12)], \n",
    "          [\"exp_bit_length\", \"exp_hamming\", \"group_limbs\"],\n",
    "                              \"final_exp_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    return model_final_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal final exp fitting score = 0.0\n",
      "    modulus_limbs  group_limbs  final_exp_time  exp_bit_length  exp_hamming\n",
      "0             4.0          5.0     1328.070700          1633.0        935.0\n",
      "6             9.0          1.0     5716.329890          2797.0       2392.0\n",
      "12            4.0          9.0     2590.268627          2576.0       1164.0\n",
      "18            8.0          9.0     4567.731398          2591.0       1702.0\n",
      "24            9.0         16.0    10856.607929          2332.0       1370.0\n",
      "36            5.0          4.0     1954.445818          1364.0        164.0\n",
      "42           13.0         14.0    17307.979277          1155.0         62.0\n",
      "48           13.0          4.0     9104.556091          2085.0       1955.0\n",
      "60           11.0          5.0     7750.755903          1339.0        120.0\n",
      "66           14.0          1.0    10698.110285          2808.0        992.0\n",
      "Fitting final exp price\n",
      "['modulus_limbs^1*exp_bit_length', 'modulus_limbs^1*exp_hamming', 'modulus_limbs^1*group_limbs', 'modulus_limbs^2*exp_bit_length', 'modulus_limbs^2*exp_hamming', 'modulus_limbs^2*group_limbs', 'modulus_limbs^3*exp_bit_length', 'modulus_limbs^3*exp_hamming', 'modulus_limbs^3*group_limbs', 'modulus_limbs^4*exp_bit_length', 'modulus_limbs^4*exp_hamming', 'modulus_limbs^4*group_limbs', 'modulus_limbs^5*exp_bit_length', 'modulus_limbs^5*exp_hamming', 'modulus_limbs^5*group_limbs', 'modulus_limbs^6*exp_bit_length', 'modulus_limbs^6*exp_hamming', 'modulus_limbs^6*group_limbs', 'modulus_limbs^7*exp_bit_length', 'modulus_limbs^7*exp_hamming', 'modulus_limbs^7*group_limbs', 'modulus_limbs^8*exp_bit_length', 'modulus_limbs^8*exp_hamming', 'modulus_limbs^8*group_limbs', 'modulus_limbs^9*exp_bit_length', 'modulus_limbs^9*exp_hamming', 'modulus_limbs^9*group_limbs', 'modulus_limbs^10*exp_bit_length', 'modulus_limbs^10*exp_hamming', 'modulus_limbs^10*group_limbs', 'modulus_limbs^11*exp_bit_length', 'modulus_limbs^11*exp_hamming', 'modulus_limbs^11*group_limbs', 'modulus_limbs^12*exp_bit_length', 'modulus_limbs^12*exp_hamming', 'modulus_limbs^12*group_limbs']\n",
      "Train samples 29468, test samples 3275\n",
      "Intercept = 0.0\n",
      "score on training set -0.030648744552885576\n",
      "score on test set -0.03917697342560511\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 117059.16162055099 microseconds\n",
      "Mean absolute error 12486.966289908336 microseconds\n",
      "R2 score = -0.03917697342560511\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 117059.16162055099 microseconds\n",
      "Mean absolute error 12486.966289908336 microseconds\n",
      "R2 score = -0.03917697342560511\n"
     ]
    }
   ],
   "source": [
    "mnt4_final_exp_alt = analyze_mnt_final_exp_manual_reduced_features(dataframes[2], trunc_limit = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
