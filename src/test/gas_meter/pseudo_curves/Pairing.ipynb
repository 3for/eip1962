{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# file_list = [(\"BLS12\", \"./bls12/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"BN\", \"./bn/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"MNT4\", \"./mnt4/monte_carlo_f_exp_50000.csv\"),\n",
    "#             (\"MNT6\", \"./mnt6/monte_carlo_f_exp_50000.csv\")]\n",
    "\n",
    "file_list = [(\"BLS12\", \"./bls12/monte_carlo_f_exp_55000.csv\"),\n",
    "            (\"BN\", \"./bn/monte_carlo_f_exp_55000.csv\"),\n",
    "            (\"MNT4\", \"./mnt4/monte_carlo_f_exp_55000.csv\"),\n",
    "            (\"MNT6\", \"./mnt6/monte_carlo_f_exp_55000.csv\")]\n",
    "\n",
    "\n",
    "\n",
    "def get_dfs(files):\n",
    "    results = []\n",
    "    for file in files:\n",
    "        (name, path) = file;\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[df[\"x_is_negative\"] == 1.0]\n",
    "        #df.loc[:,\"num_pairs\"] *= 0.5\n",
    "        df.drop(\"x_is_negative\", axis = 1, inplace = True)\n",
    "        results.append(df)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def factor_out_final_exp(df, group_by = 3, skip_bad_fits = False):\n",
    "    df_final_exps = pd.DataFrame(columns = df.columns);\n",
    "    df_final_exps.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_final_exps.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_final_exps[\"final_exp_time\"] = 0.0\n",
    "\n",
    "    df_miller_loops = pd.DataFrame(columns = df.columns);\n",
    "    df_miller_loops.drop(\"num_pairs\", axis = 1, inplace = True);\n",
    "    df_miller_loops.drop(\"run_microseconds\", axis = 1, inplace = True);\n",
    "    df_miller_loops[\"single_pair_miller_time\"] = 0.0\n",
    "\n",
    "    min_score = 1.0\n",
    "\n",
    "    for k,g in df.groupby(np.arange(len(df))//group_by):\n",
    "        reg = linear_model.LinearRegression(fit_intercept = True)\n",
    "        model = reg.fit(g[\"num_pairs\"][:, np.newaxis], g[\"run_microseconds\"][:, np.newaxis])\n",
    "        score = model.score(g[\"num_pairs\"][:, np.newaxis], g[\"run_microseconds\"][:, np.newaxis])\n",
    "        if score < min_score:\n",
    "            min_score = score\n",
    "            \n",
    "        if score < 0.90 and skip_bad_fits:\n",
    "            continue\n",
    "            \n",
    "        g_miller = g.iloc[0].copy()\n",
    "        g_miller.drop(\"run_microseconds\", inplace = True)\n",
    "        g_final_exp = g.iloc[0].copy()\n",
    "        g_final_exp.drop(\"run_microseconds\", inplace = True)\n",
    "        g_miller[\"single_pair_miller_time\"] = model.coef_[0][0];\n",
    "        g_final_exp[\"final_exp_time\"] = model.intercept_[0];\n",
    "\n",
    "        g_miller.drop(\"num_pairs\", inplace = True)\n",
    "        g_final_exp.drop(\"num_pairs\", inplace = True)\n",
    "\n",
    "        df_miller_loops = df_miller_loops.append(g_miller, verify_integrity=True)\n",
    "        df_final_exps = df_final_exps.append(g_final_exp, verify_integrity=True)\n",
    "        \n",
    "    print(\"Minimal final exp fitting score = {}\".format(min_score))\n",
    "        \n",
    "    return (df_miller_loops, df_final_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = get_dfs(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>22083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>25577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>36677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>15900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>22633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_bit_length  x_hamming_weight  modulus_limbs  group_limbs  num_pairs  \\\n",
       "0            57                39              6           16          2   \n",
       "1            57                39              6           16          4   \n",
       "2            57                39              6           16          6   \n",
       "3            64                 7              7           11          2   \n",
       "4            64                 7              7           11          4   \n",
       "\n",
       "   run_microseconds  \n",
       "0             22083  \n",
       "1             25577  \n",
       "2             36677  \n",
       "3             15900  \n",
       "4             22633  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>six_u_plus_two_bit_length</th>\n",
       "      <th>six_u_plus_two_hamming</th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>25174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>28713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>34342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   six_u_plus_two_bit_length  six_u_plus_two_hamming  modulus_limbs  \\\n",
       "0                         51                      29             10   \n",
       "1                         51                      29             10   \n",
       "2                         51                      29             10   \n",
       "3                          5                       1              6   \n",
       "4                          5                       1              6   \n",
       "\n",
       "   group_limbs  num_pairs  x_bit_length  x_hamming_weight  run_microseconds  \n",
       "0            2          2            49                29             25174  \n",
       "1            2          4            49                29             28713  \n",
       "2            2          6            49                29             34342  \n",
       "3            4          2             2                 2              7393  \n",
       "4            4          4             2                 2              8684  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>exp_w0_bit_length</th>\n",
       "      <th>exp_w0_hamming</th>\n",
       "      <th>exp_w0_is_negative</th>\n",
       "      <th>exp_w1_bit_length</th>\n",
       "      <th>exp_w1_hamming</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>1789</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>1580</td>\n",
       "      <td>1275</td>\n",
       "      <td>5357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>1789</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>1580</td>\n",
       "      <td>1275</td>\n",
       "      <td>7141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>1789</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>1580</td>\n",
       "      <td>1275</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>371</td>\n",
       "      <td>284</td>\n",
       "      <td>792</td>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "      <td>1146</td>\n",
       "      <td>669</td>\n",
       "      <td>27374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>371</td>\n",
       "      <td>284</td>\n",
       "      <td>792</td>\n",
       "      <td>321</td>\n",
       "      <td>1</td>\n",
       "      <td>1146</td>\n",
       "      <td>669</td>\n",
       "      <td>44052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modulus_limbs  group_limbs  num_pairs  x_bit_length  x_hamming_weight  \\\n",
       "0              4            2          2           119               118   \n",
       "1              4            2          4           119               118   \n",
       "2              4            2          6           119               118   \n",
       "3             10            1          2           371               284   \n",
       "4             10            1          4           371               284   \n",
       "\n",
       "   exp_w0_bit_length  exp_w0_hamming  exp_w0_is_negative  exp_w1_bit_length  \\\n",
       "0               1789             279                   1               1580   \n",
       "1               1789             279                   1               1580   \n",
       "2               1789             279                   1               1580   \n",
       "3                792             321                   1               1146   \n",
       "4                792             321                   1               1146   \n",
       "\n",
       "   exp_w1_hamming  run_microseconds  \n",
       "0            1275              5357  \n",
       "1            1275              7141  \n",
       "2            1275              8935  \n",
       "3             669             27374  \n",
       "4             669             44052  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modulus_limbs</th>\n",
       "      <th>group_limbs</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>x_bit_length</th>\n",
       "      <th>x_hamming_weight</th>\n",
       "      <th>exp_w0_bit_length</th>\n",
       "      <th>exp_w0_hamming</th>\n",
       "      <th>exp_w0_is_negative</th>\n",
       "      <th>exp_w1_bit_length</th>\n",
       "      <th>exp_w1_hamming</th>\n",
       "      <th>run_microseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1917</td>\n",
       "      <td>1474</td>\n",
       "      <td>1601</td>\n",
       "      <td>1371</td>\n",
       "      <td>1</td>\n",
       "      <td>672</td>\n",
       "      <td>17</td>\n",
       "      <td>219275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1917</td>\n",
       "      <td>1474</td>\n",
       "      <td>1601</td>\n",
       "      <td>1371</td>\n",
       "      <td>1</td>\n",
       "      <td>672</td>\n",
       "      <td>17</td>\n",
       "      <td>402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1917</td>\n",
       "      <td>1474</td>\n",
       "      <td>1601</td>\n",
       "      <td>1371</td>\n",
       "      <td>1</td>\n",
       "      <td>672</td>\n",
       "      <td>17</td>\n",
       "      <td>606740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1740</td>\n",
       "      <td>1291</td>\n",
       "      <td>765</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>898</td>\n",
       "      <td>478</td>\n",
       "      <td>215073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1740</td>\n",
       "      <td>1291</td>\n",
       "      <td>765</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>898</td>\n",
       "      <td>478</td>\n",
       "      <td>425829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modulus_limbs  group_limbs  num_pairs  x_bit_length  x_hamming_weight  \\\n",
       "0              9            9          2          1917              1474   \n",
       "1              9            9          4          1917              1474   \n",
       "2              9            9          6          1917              1474   \n",
       "3             11            3          2          1740              1291   \n",
       "4             11            3          4          1740              1291   \n",
       "\n",
       "   exp_w0_bit_length  exp_w0_hamming  exp_w0_is_negative  exp_w1_bit_length  \\\n",
       "0               1601            1371                   1                672   \n",
       "1               1601            1371                   1                672   \n",
       "2               1601            1371                   1                672   \n",
       "3                765             646                   1                898   \n",
       "4                765             646                   1                898   \n",
       "\n",
       "   exp_w1_hamming  run_microseconds  \n",
       "0              17            219275  \n",
       "1              17            402700  \n",
       "2              17            606740  \n",
       "3             478            215073  \n",
       "4             478            425829  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_df(df):\n",
    "    train, test = train_test_split(\n",
    "        df, test_size=0.10, random_state=42)\n",
    "    \n",
    "    print(\"Train samples {}, test samples {}\".format(len(train), len(test)))\n",
    "    \n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import max_error, mean_absolute_error, r2_score\n",
    "\n",
    "def pretty_print_polynomial(poly, model, variable_names):\n",
    "    terms = []\n",
    "\n",
    "    for term_idx in range(0, poly.powers_.shape[0]):\n",
    "        coeff = model.coef_[term_idx]\n",
    "        if coeff == 0:\n",
    "            continue\n",
    "        coeff = np.around(coeff, decimals=6)\n",
    "        subparts = []\n",
    "        coeff_string = \"{}\".format(coeff)\n",
    "        subparts.append(coeff_string)\n",
    "        for variable_idx in range(0, poly.powers_.shape[1]):\n",
    "            power = poly.powers_[term_idx, variable_idx]\n",
    "            if power != 0:\n",
    "                term_string = '{}^{}'.format(variable_names[variable_idx], power)\n",
    "                subparts.append(term_string)\n",
    "        if len(subparts) != 0:\n",
    "            joined = \" * \".join(subparts)\n",
    "            terms.append(joined)\n",
    "\n",
    "    polynomial_string = \" + \".join(terms)\n",
    "    print(polynomial_string)\n",
    "    \n",
    "\n",
    "\n",
    "def analyze(train, test, features, target, trunc_limit = 0.001, degree = 6):\n",
    "    poly = PolynomialFeatures(degree = degree, include_bias = False)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "\n",
    "    X_train = poly.fit_transform(X_train)\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000,fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "\n",
    "    X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "    pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bls12(df):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\")\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\"], \"final_exp_time\")\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples 9518, test samples 1058\n",
      "Fitting miller loop price\n",
      "score on training set 0.9779719430591235\n",
      "score on test set 0.9802756246130122\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 7473.377580372722 microseconds\n",
      "Mean absolute error 546.5861013689263 microseconds\n",
      "R2 score = 0.9802756246130122\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 7495.086831763099 microseconds\n",
      "Mean absolute error 543.9214730284359 microseconds\n",
      "R2 score = 0.980351845515199\n",
      "0.378077 * x_bit_length^1 * modulus_limbs^1 + 0.101827 * x_hamming_weight^1 * modulus_limbs^1 + 18.116865 * modulus_limbs^1 * group_limbs^1 + 0.001745 * x_bit_length^1 * x_hamming_weight^1 * modulus_limbs^1 + 0.142627 * x_bit_length^1 * modulus_limbs^2 + 0.009235 * x_bit_length^1 * modulus_limbs^1 * group_limbs^1 + 0.169045 * x_hamming_weight^1 * modulus_limbs^2 + 4.770556 * modulus_limbs^2 * group_limbs^1 + 0.0016 * modulus_limbs^2 * group_limbs^2\n",
      "Train samples 9518, test samples 1058\n",
      "Fitting final exp price\n",
      "score on training set 0.9500856763861539\n",
      "score on test set 0.9520118091392654\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 35312.04890582709 microseconds\n",
      "Mean absolute error 2243.9266280203115 microseconds\n",
      "R2 score = 0.9520118091392654\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 35353.167353160716 microseconds\n",
      "Mean absolute error 2242.9614388770183 microseconds\n",
      "R2 score = 0.9519854307104767\n",
      "6.863697 * x_bit_length^1 + 2.791031 * x_hamming_weight^1 + 1.229772 * x_bit_length^1 * modulus_limbs^1 + 3.496346 * x_hamming_weight^1 * modulus_limbs^1 + 61.389245 * modulus_limbs^2 + 0.291468 * x_bit_length^1 * modulus_limbs^2 + 0.53142 * x_hamming_weight^1 * modulus_limbs^2 + 5.091372 * modulus_limbs^3 + 0.009535 * x_bit_length^1 * modulus_limbs^3\n"
     ]
    }
   ],
   "source": [
    "(bls_miller, bls_final_exp) = analyze_bls12(dataframes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bn(df):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"six_u_plus_two_bit_length\", \"six_u_plus_two_hamming\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\")\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\"], \"final_exp_time\")\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples 9417, test samples 1047\n",
      "Fitting miller loop price\n",
      "score on training set 0.9803164741835472\n",
      "score on test set 0.9829824004300713\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 6485.833986781602 microseconds\n",
      "Mean absolute error 534.4015268817641 microseconds\n",
      "R2 score = 0.9829824004300713\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 6350.113315148997 microseconds\n",
      "Mean absolute error 530.9770159313209 microseconds\n",
      "R2 score = 0.9832223185306923\n",
      "0.236925 * six_u_plus_two_bit_length^1 * modulus_limbs^1 + 0.061988 * six_u_plus_two_hamming^1 * modulus_limbs^1 + 19.127274 * modulus_limbs^1 * group_limbs^1 + 0.002667 * six_u_plus_two_bit_length^1 * six_u_plus_two_hamming^1 * modulus_limbs^1 + 0.157434 * six_u_plus_two_bit_length^1 * modulus_limbs^2 + 0.15528 * six_u_plus_two_hamming^1 * modulus_limbs^2 + 4.772966 * modulus_limbs^2 * group_limbs^1\n",
      "Train samples 9417, test samples 1047\n",
      "Fitting final exp price\n",
      "score on training set 0.9425430174610224\n",
      "score on test set 0.94671180625913\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 38230.982839937504 microseconds\n",
      "Mean absolute error 2160.759306454798 microseconds\n",
      "R2 score = 0.94671180625913\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 38231.3971535435 microseconds\n",
      "Mean absolute error 2157.0853163214824 microseconds\n",
      "R2 score = 0.9467561927276554\n",
      "5.78468 * x_bit_length^1 + 2.49113 * x_hamming_weight^1 + 34.376482 * modulus_limbs^1 + 0.805863 * x_bit_length^1 * modulus_limbs^1 + 1.118058 * x_hamming_weight^1 * modulus_limbs^1 + 58.524132 * modulus_limbs^2 + 0.272363 * x_bit_length^1 * modulus_limbs^2 + 0.38585 * x_hamming_weight^1 * modulus_limbs^2 + 5.349766 * modulus_limbs^3 + 0.001198 * x_bit_length^1 * modulus_limbs^3 + 0.032844 * modulus_limbs^4\n"
     ]
    }
   ],
   "source": [
    "(bn_miller, bn_final_exp) = analyze_bn(dataframes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "    (train, test) = split_df(miller)\n",
    "    print(\"Fitting miller loop price\")\n",
    "    model_miller = analyze(train, test, [\"x_bit_length\", \"x_hamming_weight\", \"modulus_limbs\", \"group_limbs\"], \"single_pair_miller_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    (train, test) = split_df(final_exp)\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze(train, test, [\"exp_w0_bit_length\", \"exp_w0_hamming\", \"exp_w1_bit_length\", \"exp_w1_hamming\", \"modulus_limbs\"], \"final_exp_time\", trunc_limit = trunc_limit, degree = 6)\n",
    "    \n",
    "    return (model_miller, model_final_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples 9458, test samples 1051\n",
      "Fitting miller loop price\n",
      "score on training set 0.990810453612425\n",
      "score on test set 0.9872677133226724\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 31709.005569665227 microseconds\n",
      "Mean absolute error 1529.0306499396045 microseconds\n",
      "R2 score = 0.9872677133226724\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 32910.466579074986 microseconds\n",
      "Mean absolute error 1538.029793019711 microseconds\n",
      "R2 score = 0.9869416414732952\n",
      "0.483096 * x_bit_length^1 * modulus_limbs^1 + 0.249595 * x_hamming_weight^1 * modulus_limbs^1 + 1.343401 * modulus_limbs^2 + 22.410234 * modulus_limbs^1 * group_limbs^1 + 0.100338 * x_bit_length^1 * modulus_limbs^2 + 0.097977 * x_hamming_weight^1 * modulus_limbs^2 + 5.759813 * modulus_limbs^2 * group_limbs^1 + 0.0179 * modulus_limbs^1 * group_limbs^2 + 0.005582 * modulus_limbs^1 * group_limbs^3\n",
      "Train samples 9458, test samples 1051\n",
      "Fitting final exp price\n",
      "score on training set 0.18386050604623883\n",
      "score on test set 0.199201675315813\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 91033.49853095609 microseconds\n",
      "Mean absolute error 3554.3576410810447 microseconds\n",
      "R2 score = 0.199201675315813\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 91018.22858658605 microseconds\n",
      "Mean absolute error 3637.442993459978 microseconds\n",
      "R2 score = 0.1850196416487645\n",
      "0.394929 * exp_w0_bit_length^1 + 0.346636 * exp_w1_bit_length^1 + 183.544482 * modulus_limbs^1 + 0.009184 * exp_w0_bit_length^1 * modulus_limbs^1 + 0.010157 * exp_w0_bit_length^1 * modulus_limbs^2 + 0.009698 * exp_w1_bit_length^1 * modulus_limbs^2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train samples 9458, test samples 1051\n",
      "Fitting miller loop price\n",
      "score on training set 0.990810453612425\n",
      "score on test set 0.9872677133226724\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 31709.005569665227 microseconds\n",
      "Mean absolute error 1529.0306499396045 microseconds\n",
      "R2 score = 0.9872677133226724\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 31709.005569665227 microseconds\n",
      "Mean absolute error 1529.0306499396045 microseconds\n",
      "R2 score = 0.9872677133226724\n",
      "0.483096 * x_bit_length^1 * modulus_limbs^1 + 0.249595 * x_hamming_weight^1 * modulus_limbs^1 + 1.343401 * modulus_limbs^2 + 22.410234 * modulus_limbs^1 * group_limbs^1 + 0.100338 * x_bit_length^1 * modulus_limbs^2 + 1.1e-05 * x_hamming_weight^2 * modulus_limbs^1 + 0.097977 * x_hamming_weight^1 * modulus_limbs^2 + 5.759813 * modulus_limbs^2 * group_limbs^1 + 0.0179 * modulus_limbs^1 * group_limbs^2 + 2e-06 * x_bit_length^2 * modulus_limbs^2 + 0.0 * x_hamming_weight^3 * modulus_limbs^1 + 0.005582 * modulus_limbs^1 * group_limbs^3 + 8.1e-05 * modulus_limbs^1 * group_limbs^4 + 0.0 * x_hamming_weight^4 * modulus_limbs^2\n",
      "Train samples 9458, test samples 1051\n",
      "Fitting final exp price\n",
      "score on training set 0.18386050604623883\n",
      "score on test set 0.199201675315813\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 91033.49853095609 microseconds\n",
      "Mean absolute error 3554.3576410810447 microseconds\n",
      "R2 score = 0.199201675315813\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 91033.49853095609 microseconds\n",
      "Mean absolute error 3554.3576410810447 microseconds\n",
      "R2 score = 0.199201675315813\n",
      "0.394929 * exp_w0_bit_length^1 + 0.346636 * exp_w1_bit_length^1 + 183.544482 * modulus_limbs^1 + 0.009184 * exp_w0_bit_length^1 * modulus_limbs^1 + 0.010157 * exp_w0_bit_length^1 * modulus_limbs^2 + 0.009698 * exp_w1_bit_length^1 * modulus_limbs^2 + 0.000215 * exp_w1_bit_length^1 * modulus_limbs^3 + 0.0 * exp_w1_hamming^1 * modulus_limbs^5 + 0.0 * exp_w1_hamming^1 * modulus_limbs^6 + 0.0 * exp_w0_bit_length^12 + 0.0 * exp_w0_bit_length^11 * modulus_limbs^1 + 0.0 * exp_w0_hamming^5 * exp_w1_hamming^1 * modulus_limbs^6 + 0.0 * exp_w0_hamming^3 * exp_w1_hamming^9 + 0.0 * exp_w0_hamming^2 * exp_w1_hamming^10 + 0.0 * exp_w1_bit_length^9 * modulus_limbs^3 + 0.0 * exp_w1_bit_length^8 * modulus_limbs^4 + 0.0 * exp_w1_hamming^11 * modulus_limbs^1\n"
     ]
    }
   ],
   "source": [
    "(mnt4_miller, mnt4_final_exp) = analyze_mnt(dataframes[2], trunc_limit = 0.001)\n",
    "print(\"\\n\\n\\n\")\n",
    "(mnt4_miller, mnt4_final_exp) = analyze_mnt(dataframes[2], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples 9382, test samples 1043\n",
      "Fitting miller loop price\n",
      "score on training set 0.9909648771792469\n",
      "score on test set 0.9933533841953999\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 26636.078553710657 microseconds\n",
      "Mean absolute error 2424.7407084245783 microseconds\n",
      "R2 score = 0.9933533841954\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 28089.403434414242 microseconds\n",
      "Mean absolute error 2463.733056306811 microseconds\n",
      "R2 score = 0.9932667326223179\n",
      "1.043465 * x_bit_length^1 * modulus_limbs^1 + 0.666413 * x_hamming_weight^1 * modulus_limbs^1 + 2.398405 * modulus_limbs^2 + 43.091255 * modulus_limbs^1 * group_limbs^1 + 0.174695 * x_bit_length^1 * modulus_limbs^2 + 0.181491 * x_hamming_weight^1 * modulus_limbs^2 + 9.441175 * modulus_limbs^2 * group_limbs^1\n",
      "Train samples 9382, test samples 1043\n",
      "Fitting final exp price\n",
      "score on training set 0.22623654365401533\n",
      "score on test set 0.22359767651921092\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 187115.9956651702 microseconds\n",
      "Mean absolute error 5500.24555167281 microseconds\n",
      "R2 score = 0.22359767651921092\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 187392.51688150782 microseconds\n",
      "Mean absolute error 5469.26071280971 microseconds\n",
      "R2 score = 0.22537560078562957\n",
      "0.246173 * exp_w0_hamming^1 + 132.174163 * modulus_limbs^1 + 0.105928 * exp_w0_bit_length^1 * modulus_limbs^1 + 0.137609 * exp_w1_bit_length^1 * modulus_limbs^1 + 0.02587 * exp_w0_bit_length^1 * modulus_limbs^2 + 0.020489 * exp_w1_bit_length^1 * modulus_limbs^2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Train samples 9382, test samples 1043\n",
      "Fitting miller loop price\n",
      "score on training set 0.9909648771792469\n",
      "score on test set 0.9933533841953999\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 26636.078553710657 microseconds\n",
      "Mean absolute error 2424.7407084245783 microseconds\n",
      "R2 score = 0.9933533841954\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 26636.078553710657 microseconds\n",
      "Mean absolute error 2424.7407084245783 microseconds\n",
      "R2 score = 0.9933533841954\n",
      "1.043465 * x_bit_length^1 * modulus_limbs^1 + 0.666413 * x_hamming_weight^1 * modulus_limbs^1 + 2.398405 * modulus_limbs^2 + 43.091255 * modulus_limbs^1 * group_limbs^1 + 0.174695 * x_bit_length^1 * modulus_limbs^2 + 0.181491 * x_hamming_weight^1 * modulus_limbs^2 + 9.441175 * modulus_limbs^2 * group_limbs^1 + 3e-06 * x_bit_length^2 * modulus_limbs^2 + 0.000121 * x_bit_length^1 * modulus_limbs^2 * group_limbs^1 + 1.9e-05 * modulus_limbs^1 * group_limbs^5\n",
      "Train samples 9382, test samples 1043\n",
      "Fitting final exp price\n",
      "score on training set 0.22623654365401533\n",
      "score on test set 0.22359767651921092\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 187115.9956651702 microseconds\n",
      "Mean absolute error 5500.24555167281 microseconds\n",
      "R2 score = 0.22359767651921092\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 187115.9956651702 microseconds\n",
      "Mean absolute error 5500.24555167281 microseconds\n",
      "R2 score = 0.22359767651921092\n",
      "0.246173 * exp_w0_hamming^1 + 132.174163 * modulus_limbs^1 + 0.105928 * exp_w0_bit_length^1 * modulus_limbs^1 + 0.137609 * exp_w1_bit_length^1 * modulus_limbs^1 + 0.02587 * exp_w0_bit_length^1 * modulus_limbs^2 + 0.020489 * exp_w1_bit_length^1 * modulus_limbs^2 + 6.4e-05 * exp_w0_bit_length^1 * modulus_limbs^3 + 0.0 * exp_w0_bit_length^1 * exp_w1_hamming^3 * modulus_limbs^2 + 0.0 * exp_w1_bit_length^6 + 0.0 * exp_w1_bit_length^5 * modulus_limbs^1\n"
     ]
    }
   ],
   "source": [
    "(mnt6_miller, mnt6_final_exp) = analyze_mnt(dataframes[3], trunc_limit = 0.001)\n",
    "print(\"\\n\\n\\n\")\n",
    "(mnt6_miller, mnt6_final_exp) = analyze_mnt(dataframes[3], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_manual_poly(df, features_description, target, trunc_limit = 0.001, degree = 3):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    features = []\n",
    "    for feature in features_description:\n",
    "        name, max_power = feature\n",
    "        for i in range(1, max_power+1):\n",
    "            subname = \"{}^{}\".format(name, i)\n",
    "            new_df[subname] = new_df[name].apply(lambda x: x**i)\n",
    "            features.append(subname)\n",
    "            \n",
    "    print(features)\n",
    "            \n",
    "    poly = PolynomialFeatures(degree = degree, interaction_only=True, include_bias = False)\n",
    "        \n",
    "    train, test = split_df(new_df)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "    \n",
    "    X_train = poly.fit_transform(X_train)\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000, fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Intercept = {}\".format(lin.intercept_))\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "    \n",
    "    X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "    pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt_final_exp(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df)\n",
    "\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze_manual_poly(final_exp, [\n",
    "        (\"exp_w0_bit_length\", 1), \n",
    "        (\"exp_w0_hamming\", 1), \n",
    "        (\"exp_w1_bit_length\", 1),\n",
    "        (\"exp_w1_hamming\", 1),\n",
    "        (\"modulus_limbs\", 12)], \"final_exp_time\", trunc_limit = trunc_limit, degree = 2)\n",
    "    \n",
    "    return model_final_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final exp price\n",
      "['exp_w0_bit_length^1', 'exp_w0_hamming^1', 'exp_w1_bit_length^1', 'exp_w1_hamming^1', 'modulus_limbs^1', 'modulus_limbs^2', 'modulus_limbs^3', 'modulus_limbs^4', 'modulus_limbs^5', 'modulus_limbs^6', 'modulus_limbs^7', 'modulus_limbs^8', 'modulus_limbs^9', 'modulus_limbs^10', 'modulus_limbs^11', 'modulus_limbs^12']\n",
      "Train samples 9458, test samples 1051\n",
      "Intercept = 1001.4321467581049\n",
      "score on training set 0.18283416211974268\n",
      "score on test set 0.20068930079748215\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 90828.97592921303 microseconds\n",
      "Mean absolute error 3546.7899559125362 microseconds\n",
      "R2 score = 0.20068930079748215\n",
      "Truncating coefficients lower than 0.001\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 90826.66158626825 microseconds\n",
      "Mean absolute error 3549.061775152095 microseconds\n",
      "R2 score = 0.2001105835525162\n",
      "0.136533 * exp_w0_bit_length^1^1 + 0.143178 * exp_w1_bit_length^1^1 + 5.843775 * modulus_limbs^2^1 + 0.05817 * exp_w0_bit_length^1^1 * modulus_limbs^1^1 + 0.009198 * exp_w0_bit_length^1^1 * modulus_limbs^2^1 + 0.015435 * exp_w1_bit_length^1^1 * modulus_limbs^2^1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting final exp price\n",
      "['exp_w0_bit_length^1', 'exp_w0_hamming^1', 'exp_w1_bit_length^1', 'exp_w1_hamming^1', 'modulus_limbs^1', 'modulus_limbs^2', 'modulus_limbs^3', 'modulus_limbs^4', 'modulus_limbs^5', 'modulus_limbs^6', 'modulus_limbs^7', 'modulus_limbs^8', 'modulus_limbs^9', 'modulus_limbs^10', 'modulus_limbs^11', 'modulus_limbs^12']\n",
      "Train samples 9458, test samples 1051\n",
      "Intercept = 1001.4321467581049\n",
      "score on training set 0.18283416211974268\n",
      "score on test set 0.20068930079748215\n",
      "Model accuracy before manual truncation of coefficients\n",
      "Max absolute error 90828.97592921303 microseconds\n",
      "Mean absolute error 3546.7899559125362 microseconds\n",
      "R2 score = 0.20068930079748215\n",
      "Truncating coefficients lower than 0.0\n",
      "Model accuracy after manual truncation of coefficients\n",
      "Max absolute error 90828.97592921303 microseconds\n",
      "Mean absolute error 3546.7899559125362 microseconds\n",
      "R2 score = 0.20068930079748215\n",
      "0.136533 * exp_w0_bit_length^1^1 + 0.143178 * exp_w1_bit_length^1^1 + 5.843775 * modulus_limbs^2^1 + 0.05817 * exp_w0_bit_length^1^1 * modulus_limbs^1^1 + 0.009198 * exp_w0_bit_length^1^1 * modulus_limbs^2^1 + 2.8e-05 * exp_w0_hamming^1^1 * exp_w1_hamming^1^1 + 0.015435 * exp_w1_bit_length^1^1 * modulus_limbs^2^1 + 3e-06 * exp_w1_hamming^1^1 * modulus_limbs^4^1\n"
     ]
    }
   ],
   "source": [
    "mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.001)\n",
    "# print(\"\\n\\n\\n\") \n",
    "# mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_manual_poly_separated(df, powered_features, linear_features, target, trunc_limit = 0.001):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    sub_features = []\n",
    "    for feature in powered_features:\n",
    "        name, max_power = feature\n",
    "        for i in range(1, max_power+1):\n",
    "            subname = \"{}^{}\".format(name, i)\n",
    "            new_df[subname] = new_df[name].apply(lambda x: x**i)\n",
    "            sub_features.append(subname)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for subfeature in sub_features:\n",
    "        for lin_feature in linear_features:\n",
    "            subname = \"{}*{}\".format(subfeature, lin_feature)\n",
    "            new_df[subname] = new_df.apply(lambda row: (row[subfeature]*row[lin_feature]), axis=1)\n",
    "            features.append(subname)\n",
    "            \n",
    "            \n",
    "    print(features)\n",
    "        \n",
    "    train, test = split_df(new_df)\n",
    "\n",
    "    X_train = train[features]\n",
    "    Y_train = train[target]\n",
    "\n",
    "    lin = Lasso(alpha=0.0001,precompute=True, max_iter=100000, fit_intercept=False,\n",
    "                positive=True, random_state=9999, selection='random')\n",
    "    lin.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Intercept = {}\".format(lin.intercept_))\n",
    "\n",
    "    print(\"score on training set {}\".format(lin.score(X_train, Y_train)))\n",
    "\n",
    "    X_test = test[features]\n",
    "    Y_test = test[target]\n",
    "\n",
    "    print(\"score on test set {}\".format(lin.score(X_test, Y_test)))\n",
    "    \n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Model accuracy before manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "\n",
    "    coeffs = lin.coef_.copy()\n",
    "    for k in range(0, coeffs.shape[0]):\n",
    "        c = coeffs[k]\n",
    "        if c < trunc_limit:\n",
    "            coeffs[k] = 0.0\n",
    "\n",
    "    lin.coef_ = coeffs\n",
    "\n",
    "    y_true = Y_test\n",
    "    y_pred = lin.predict(X_test)\n",
    "\n",
    "    print(\"Truncating coefficients lower than {}\".format(trunc_limit))\n",
    "    print(\"Model accuracy after manual truncation of coefficients\")\n",
    "    print(\"Max absolute error {} microseconds\".format(max_error(y_true, y_pred)))\n",
    "    print(\"Mean absolute error {} microseconds\".format(mean_absolute_error(y_true, y_pred)))\n",
    "    print(\"R2 score = {}\".format(r2_score(y_true, y_pred)))\n",
    "    \n",
    "#     pretty_print_polynomial(poly, lin, features)\n",
    "    \n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mnt_final_exp_manual(df, trunc_limit = 0.001):\n",
    "    (miller, final_exp) = factor_out_final_exp(df, skip_bad_fits = True)\n",
    "    \n",
    "    print(final_exp.head(25))\n",
    "\n",
    "    print(\"Fitting final exp price\")\n",
    "    model_final_exp = analyze_manual_poly_separated(final_exp, [\n",
    "        (\"modulus_limbs\", 12)], \n",
    "          [\"exp_w0_bit_length\", \"exp_w0_hamming\",\"exp_w1_bit_length\",\"exp_w1_hamming\"],\n",
    "                              \"final_exp_time\", trunc_limit = trunc_limit)\n",
    "    \n",
    "    return model_final_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnt4_final_exp_alt = analyze_mnt_final_exp_manual(dataframes[2], trunc_limit = 0.001)\n",
    "# print(\"\\n\\n\\n\") \n",
    "# mnt4_final_exp_alt = analyze_mnt_final_exp(dataframes[2], trunc_limit = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
